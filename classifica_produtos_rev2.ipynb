{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EM TESTES\n",
    "#VERSAO COM VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Embedding,\n",
    "    LSTM,\n",
    "    Attention,\n",
    "    Dropout,\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    "    GlobalAveragePooling1D,\n",
    "    concatenate,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import webcolors\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from typing import Tuple, Dict, List, Optional, Union\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, use_scale=True, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "        self.use_scale = use_scale\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w_q = self.add_weight(\n",
    "            name='w_q',\n",
    "            shape=(input_shape[-1], input_shape[-1]),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.w_k = self.add_weight(\n",
    "            name='w_k',\n",
    "            shape=(input_shape[-1], input_shape[-1]),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        q = tf.matmul(inputs, self.w_q)\n",
    "        k = tf.matmul(inputs, self.w_k)\n",
    "        v = inputs\n",
    "        if self.use_scale:\n",
    "            q /= tf.sqrt(tf.cast(tf.shape(k)[-1], tf.float32))\n",
    "        attn_scores = tf.matmul(q, k, transpose_b=True)\n",
    "        attn_scores = tf.nn.softmax(attn_scores, axis=-1)\n",
    "        output = tf.matmul(attn_scores, v)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "\n",
    "def identify_colors(image: np.ndarray) -> List[Dict[str, str]]:\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    small_image = cv2.resize(image_rgb, (100, 100))\n",
    "    color_list = small_image.reshape(-1, small_image.shape[-1])\n",
    "    color_info = []\n",
    "    for color in color_list:\n",
    "        try:\n",
    "            closest_color = webcolors.rgb_to_name(color)\n",
    "            color_hex = \"#{:02x}{:02x}{:02x}\".format(color[0], color[1], color[2])\n",
    "            color_info.append({'name': closest_color, 'hex': color_hex})\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    unique_colors = []\n",
    "    for color in color_info:\n",
    "        if color not in unique_colors:\n",
    "            unique_colors.append(color)\n",
    "    return unique_colors\n",
    "\n",
    "def process_image(image_path: str, resize: bool = True) -> Tuple[Optional[np.ndarray], Optional[str]]:\n",
    "    if image_path.startswith('http'):\n",
    "        response = requests.get(image_path)\n",
    "        if response.status_code == 200:\n",
    "            img_data = BytesIO(response.content)\n",
    "            img = cv2.imdecode(np.frombuffer(img_data.read(), np.uint8), 1)\n",
    "            if img is not None:\n",
    "                if resize:\n",
    "                    img = cv2.resize(img, (300, 300))\n",
    "                return img, image_path\n",
    "    elif os.path.exists(image_path):\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is not None:\n",
    "            if resize:\n",
    "                img = cv2.resize(img, (300, 300))\n",
    "            return img, image_path\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def calculate_text_similarity(text1: str, text2: str) -> float:\n",
    "    set1 = set(text1.lower().split())\n",
    "    set2 = set(text2.lower().split())\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union) if len(union) > 0 else 0.0\n",
    "\n",
    "\n",
    "\n",
    "def calculate_image_similarity(image1: np.ndarray, image2: np.ndarray) -> float:\n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "  \n",
    "    image1 = cv2.resize(image1, (224, 224))\n",
    "    image1 = np.expand_dims(image1, axis=0)\n",
    "    image1 = preprocess_input(image1)\n",
    "\n",
    "    image2 = cv2.resize(image2, (224, 224))\n",
    "    image2 = np.expand_dims(image2, axis=0)\n",
    "    image2 = preprocess_input(image2)\n",
    "\n",
    "  \n",
    "    features1 = vgg16.predict(image1)\n",
    "    features2 = vgg16.predict(image2)\n",
    "\n",
    "    \n",
    "    similarity = np.dot(features1.flatten(), features2.flatten())\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def compare_images_with_reference(reference_image: np.ndarray, image_list: List[np.ndarray]) -> List[float]:\n",
    "    similarities = []\n",
    "    for image in image_list:\n",
    "        similarity = calculate_image_similarity(reference_image, image)\n",
    "        similarities.append(similarity)\n",
    "    return similarities\n",
    "\n",
    "def find_matching_category(avaliacao_nome: str, treino: pd.DataFrame) -> str:\n",
    "    max_similarity = 0.0\n",
    "    matching_category = \"\"\n",
    "    for _, row_treino in treino.iterrows():\n",
    "        nome_treino = row_treino['nome']\n",
    "        similarity = calculate_text_similarity(avaliacao_nome, nome_treino)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            matching_category = row_treino['Categoria']\n",
    "    return matching_category\n",
    "\n",
    "\n",
    "def create_info_dict(nome: str, imagem: str, categoria: str, probabilidade: float) -> Dict[str, Union[str, str, float]]:\n",
    "    info_dict = {\n",
    "        'Nome Produto Avaliação': nome,\n",
    "        'Imagem': imagem,\n",
    "        'Categoria': categoria,\n",
    "        'Probabilidade': probabilidade,\n",
    "    }\n",
    "    return info_dict\n",
    "\n",
    "\n",
    "def extract_image_features(image_path: str) -> np.ndarray:\n",
    "    img, _ = process_image(image_path, resize=True)\n",
    "    if img is not None:\n",
    "        # Carregue o modelo MobileNetV2 pré-treinado\n",
    "        base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
    "                                                       include_top=False,\n",
    "                                                       weights='imagenet')\n",
    "        base_model.trainable = False  \n",
    "         # Correção: use (224, 224, 3) em vez de (300, 300, 3)\n",
    "        input_image = Input(shape=(224, 224, 3)) \n",
    "        mobilenet_output = base_model(input_image) \n",
    "\n",
    "     \n",
    "        image_features = Flatten()(mobilenet_output)  \n",
    "        return image_features\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "root_dir: str = r'D:\\imagesapp\\images'  \n",
    "treino: Optional[pd.DataFrame] = pd.read_csv(os.path.join(root_dir, 'images.csv'), sep=\";\")\n",
    "avaliacao: Optional[pd.DataFrame] = pd.read_csv(os.path.join(root_dir, 'avaliacao.csv'), sep=\";\")\n",
    "\n",
    "if treino is not None and avaliacao is not None:\n",
    "   \n",
    "    tokenizer: Tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(treino['nome'])\n",
    "\n",
    "    texts_train_sequences: np.ndarray = tokenizer.texts_to_sequences(treino['nome'])\n",
    "    max_sequence_length: int = 300\n",
    "    texts_train_sequences = pad_sequences(texts_train_sequences, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "    text_vocab_size: int = len(tokenizer.word_index) + 1\n",
    "\n",
    "  \n",
    "    image_features_list = []\n",
    "    for _, row_avaliacao in avaliacao.dropna().iterrows():\n",
    "        imagem_avaliacao = row_avaliacao['imagem']\n",
    "        image_features = extract_image_features(imagem_avaliacao)\n",
    "        image_features_list.append(image_features)\n",
    "\n",
    "  \n",
    "    image_features_array = np.array(image_features_list)\n",
    "\n",
    "\n",
    "    input_text: tf.Tensor = Input(shape=(max_sequence_length,), dtype=tf.int32)\n",
    "    text_model: tf.keras.Model = tf.keras.Sequential([\n",
    "        Embedding(input_dim=text_vocab_size, output_dim=256, input_length=max_sequence_length),\n",
    "        LSTM(512, return_sequences=True),\n",
    "        LSTM(512, return_sequences=True),\n",
    "        AttentionLayer(use_scale=True),\n",
    "        GlobalAveragePooling1D(),\n",
    "    ])\n",
    "    text_output: tf.Tensor = text_model(input_text)\n",
    "\n",
    "  \n",
    "    combined: tf.Tensor = concatenate([image_features_array, text_output])\n",
    "    x: tf.Tensor = Dense(2048, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(combined)\n",
    "    x = Dropout(0.6)(x)\n",
    "    output: tf.Tensor = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model: tf.keras.Model = Model(inputs=[input_image, input_text], outputs=output)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    avaliacao_info_list: List[Dict[str, Union[str, str, float]]] = []\n",
    "\n",
    " \n",
    "    reference_image = treino.iloc[0]['imagem']\n",
    "\n",
    "    for _, row_avaliacao in avaliacao.dropna().iterrows():\n",
    "        nome_avaliacao = row_avaliacao['nome']\n",
    "        imagem_avaliacao = row_avaliacao['imagem']\n",
    "\n",
    "        img, _ = process_image(imagem_avaliacao)\n",
    "\n",
    "        if img is not None:\n",
    "            \n",
    "            similarity = calculate_image_similarity(img, reference_image)\n",
    "\n",
    "            texto_exemplo: str = nome_avaliacao\n",
    "            texto_exemplo_sequence: np.ndarray = tokenizer.texts_to_sequences([texto_exemplo])\n",
    "            texto_exemplo_sequence = pad_sequences(texto_exemplo_sequence, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "            previsao_probabilidades: np.ndarray = model.predict([np.array([img]), texto_exemplo_sequence])\n",
    "\n",
    "            probabilidade = previsao_probabilidades[0][0]\n",
    "\n",
    "            avaliacao_categoria = nome_avaliacao\n",
    "            categoria_prevista = find_matching_category(avaliacao_categoria, treino)\n",
    "\n",
    "            info_dict: Dict[str, Union[str, str, float]] = create_info_dict(\n",
    "                nome_avaliacao, imagem_avaliacao, categoria_prevista, probabilidade\n",
    "            )\n",
    "\n",
    "            print(\"Informações do Produto Avaliação:\")\n",
    "            for key, value in info_dict.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "\n",
    "            cores_identificadas: List[Dict[str, str]] = identify_colors(img)\n",
    "            for color_info in cores_identificadas:\n",
    "                print(f\"Nome da Cor: {color_info['name']}\")\n",
    "                print(f\"Código Hexa: {color_info['hex']}\")\n",
    "\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            plt.title('Imagem do Produto')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "            print(f\"Nome do Produto Avaliação: {nome_avaliacao}\")\n",
    "            print(f\"Probabilidade: {probabilidade}\")\n",
    "\n",
    "            avaliacao_info_list.append(info_dict)\n",
    "\n",
    "        else:\n",
    "            print(f\"Erro ao processar imagem de '{nome_avaliacao}'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
